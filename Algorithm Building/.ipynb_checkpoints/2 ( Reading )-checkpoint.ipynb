{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T05:06:02.376618Z",
     "start_time": "2021-01-19T05:06:02.350624Z"
    }
   },
   "outputs": [],
   "source": [
    "#Libraries \n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras\n",
    "from PIL import Image, ImageOps\n",
    "from keras.preprocessing import image\n",
    "import warnings\n",
    "import gc\n",
    "from itertools import permutations \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T05:06:02.406625Z",
     "start_time": "2021-01-19T05:06:02.389624Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = r\"D:\\working repos\\AltRekruit\\Testing\\Final (15jan)\\images\\good_2.jpg\"\n",
    "scores_1 = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score Calculating**\n",
    "- in functions to run mem load out of scope ( temporary implentation ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T05:06:03.070629Z",
     "start_time": "2021-01-19T05:06:02.425625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vgg_19(img_path):\n",
    "    global scores\n",
    "    vgg19 = tensorflow.keras.models.load_model(r'D:\\working repos\\AltRekruit-Models\\Models(15jan)\\Models\\vgg19.h5')\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    vgg19_score = vgg19.predict(img)\n",
    "    \n",
    "    scores_1['vgg19'] = vgg19_score\n",
    "\n",
    "    \n",
    "def vgg_16(img_path):\n",
    "    global scores\n",
    "    vgg16 = tensorflow.keras.models.load_model(r'D:\\working repos\\AltRekruit-Models\\Models(15jan)\\Models\\vgg16.h5')\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    vgg16_score = vgg16.predict(img)\n",
    "    \n",
    "    scores_1['vgg16'] = vgg16_score\n",
    "    \n",
    "\n",
    "def resnet_50(img_path):\n",
    "    global scores\n",
    "    resnet50 = tensorflow.keras.models.load_model(r'D:\\working repos\\AltRekruit-Models\\Models(15jan)\\Models\\res50.h5')\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    resnet50_score = resnet50.predict(img)\n",
    "    \n",
    "    scores_1['resnet50'] = resnet50_score\n",
    "    \n",
    "    \n",
    "def naive_model(img_path):\n",
    "    global scores\n",
    "    naive = tensorflow.keras.models.load_model(r'D:\\working repos\\AltRekruit-Models\\Models(15jan)\\Models\\naive.h5')\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    naive_score = naive.predict(img)\n",
    "    \n",
    "    scores_1['naive'] = naive_score\n",
    "    \n",
    "    \n",
    "def tm_model(img_path):\n",
    "    tm = tensorflow.keras.models.load_model(r'D:\\working repos\\AltRekruit-Models\\Models(15jan)\\Models\\tm_custom_model(image-pairs).h5')\n",
    "    \n",
    "    np.set_printoptions(suppress=True)\n",
    "    \n",
    "    tm.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "    img = Image.open(img_path)\n",
    "    size = (224, 224)\n",
    "    img = ImageOps.fit(img, size, Image.ANTIALIAS)\n",
    "    image_array = np.asarray(img)\n",
    "    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "    data[0] = normalized_image_array\n",
    "\n",
    "    tm_score = tm.predict(data)\n",
    "    \n",
    "    scores_1['tm_custom'] = tm_score\n",
    "    \n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T05:06:52.471061Z",
     "start_time": "2021-01-19T05:06:03.083632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F84A0EC4C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F84A02B318> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F84A043438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F84B50A288> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F84A00BCA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1499"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_19(img_path) ; gc.collect()\n",
    "vgg_16(img_path) ; gc.collect()\n",
    "resnet_50(img_path) ; gc.collect()\n",
    "naive_model(img_path) ; gc.collect()\n",
    "tm_model(img_path) ; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T05:06:53.692151Z",
     "start_time": "2021-01-19T05:06:52.478068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ = []\n",
    "cls_t = [] \n",
    "# 0 , 1 ,2 Where 2 means equal scores\n",
    "for key in scores_1.keys():\n",
    "    if scores_1[key][0][0]>scores_1[key][0][1]:\n",
    "        cls_t.append(0)\n",
    "        val_.append(0)\n",
    "    elif scores_1[key][0][0]<scores_1[key][0][1]:\n",
    "        val_.append(1)\n",
    "        cls_t.append(1)\n",
    "    else:\n",
    "        val_append(2)\n",
    "\n",
    "\n",
    "score_1_avg = 0\n",
    "iter_ = 0 \n",
    "for key in scores_1.keys():\n",
    "    act_val = val_[iter_]\n",
    "    score_1_avg = score_1_avg +  scores_1[key][0][act_val]\n",
    "gc.collect()\n",
    "score_1_final = (score_1_avg/5)*100\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T21:36:43.338435Z",
     "start_time": "2021-01-18T21:36:43.024258Z"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T05:06:54.276700Z",
     "start_time": "2021-01-19T05:06:53.709147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def class_finder(vgg_19,naive,btg_res,btb_vgg16,tm):\n",
    "    global vgg19_cls,naive_cls,tm_cls\n",
    "    \n",
    "    if vgg_19[0]>vgg_19[1]:\n",
    "        vgg19_cls = 0\n",
    "    else:\n",
    "        vgg19_cls = 1\n",
    "    \n",
    "        \n",
    "    if naive[0]>naive[1]:\n",
    "        naive_cls = 0\n",
    "    else:\n",
    "        naive_cls = 1\n",
    "    \n",
    "    if vgg19_cls == naive_cls:\n",
    "        \n",
    "        if vgg19_cls == 0:\n",
    "            add_on = btb_vgg16\n",
    "        else:\n",
    "            add_on = btg_res\n",
    "        return(vgg_19[vgg19_cls]+naive[vgg19_cls]+add_on[vgg19_cls])/3\n",
    "    \n",
    "    else:\n",
    "        if tm[0]>tm[1]:\n",
    "            tm_cls = 0\n",
    "            add_on = btb_vgg16\n",
    "        else:\n",
    "            tm_cls = 1\n",
    "            add_on = btg_res\n",
    "            \n",
    "        return(tm[tm_cls]+add_on[tm_cls])/2\n",
    "        \n",
    "def most_(List): \n",
    "    return max(set(List), key = List.count)\n",
    "def Average(lst): \n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "gc.collect()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T05:06:54.988699Z",
     "start_time": "2021-01-19T05:06:54.289702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#g_scores \n",
    "score_2_final_g1 = class_finder(scores_1['vgg19'][0],scores_1['resnet50'][0],scores_1['naive'][0],scores_1['vgg16'][0],scores_1['tm_custom'][0])*100\n",
    "score_2_final_g2 = class_finder(scores_1['vgg19'][0],scores_1['resnet50'][0],scores_1['tm_custom'][0],scores_1['vgg16'][0],scores_1['naive'][0])*100\n",
    "\n",
    "#b_scores\n",
    "score_2_final_b1 = class_finder(scores_1['vgg19'][0],scores_1['resnet50'][0],scores_1['naive'][0],scores_1['vgg16'][0],scores_1['tm_custom'][0])*100\n",
    "score_2_final_b2 = class_finder(scores_1['vgg19'][0],scores_1['resnet50'][0],scores_1['naive'][0],scores_1['tm_custom'][0],scores_1['vgg16'][0])*100\n",
    "\n",
    "\n",
    "\n",
    "cls_list = [[tm_cls,naive_cls,vgg19_cls],cls_t]\n",
    "cls_list_n = [item for sublist in cls_list for item in sublist]\n",
    "count_0 = cls_list_n.count(0)\n",
    "count_1 = cls_list_n.count(1)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T05:06:55.020697Z",
     "start_time": "2021-01-19T05:06:54.999694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_0,count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T05:06:55.081694Z",
     "start_time": "2021-01-19T05:06:55.051696Z"
    }
   },
   "outputs": [],
   "source": [
    "perm = permutations([score_2_final_g1,score_2_final_g2,score_2_final_b1,score_2_final_b2])\n",
    "g_score = []\n",
    "b_score = []\n",
    "for lst in list(perm):\n",
    "    g_score.append(max(lst))\n",
    "    b_score.append(min(lst))\n",
    "g_score = Average(g_score) \n",
    "b_score = Average(b_score)\n",
    "score_2_final = (b_score*count_0 + g_score*count_1)/(count_0+count_1)\n",
    "final_score = (score_1_final + score_2_final)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T05:06:55.157696Z",
     "start_time": "2021-01-19T05:06:55.127693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.51955095554392"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
