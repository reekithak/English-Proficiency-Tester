{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T18:16:24.350465Z",
     "start_time": "2021-01-19T18:16:24.338464Z"
    }
   },
   "outputs": [],
   "source": [
    "#Libraries \n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras\n",
    "from PIL import Image, ImageOps\n",
    "from keras.preprocessing import image\n",
    "import warnings\n",
    "import gc\n",
    "from itertools import permutations \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T18:16:24.366464Z",
     "start_time": "2021-01-19T18:16:24.354467Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = r\"D:\\working repos\\AltRekruit\\EV\\images\\arabic_2.jpg\"\n",
    "scores_1 = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score Calculating**\n",
    "- in functions to run mem load out of scope ( temporary implentation ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T18:16:24.618465Z",
     "start_time": "2021-01-19T18:16:24.370464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vgg_19(img_path):\n",
    "    global scores\n",
    "    vgg19 = tensorflow.keras.models.load_model(r'D:\\working repos\\AltRekruit-Models\\Models(15jan)\\Models\\vgg19.h5')\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    vgg19_score = vgg19.predict(img)\n",
    "    \n",
    "    scores_1['vgg19'] = vgg19_score\n",
    "\n",
    "    \n",
    "def vgg_16(img_path):\n",
    "    global scores\n",
    "    vgg16 = tensorflow.keras.models.load_model(r'D:\\working repos\\AltRekruit-Models\\Models(15jan)\\Models\\vgg16.h5')\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    vgg16_score = vgg16.predict(img)\n",
    "    \n",
    "    scores_1['vgg16'] = vgg16_score\n",
    "    \n",
    "\n",
    "def resnet_50(img_path):\n",
    "    global scores\n",
    "    resnet50 = tensorflow.keras.models.load_model(r'D:\\working repos\\AltRekruit-Models\\Models(15jan)\\Models\\res50.h5')\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    resnet50_score = resnet50.predict(img)\n",
    "    \n",
    "    scores_1['resnet50'] = resnet50_score\n",
    "    \n",
    "    \n",
    "def naive_model(img_path):\n",
    "    global scores\n",
    "    naive = tensorflow.keras.models.load_model(r'D:\\working repos\\AltRekruit-Models\\Models(15jan)\\Models\\naive.h5')\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    naive_score = naive.predict(img)\n",
    "    \n",
    "    scores_1['naive'] = naive_score\n",
    "    \n",
    "    \n",
    "def tm_model(img_path):\n",
    "    tm = tensorflow.keras.models.load_model(r'D:\\working repos\\AltRekruit-Models\\Models(15jan)\\Models\\tm_custom_model(image-pairs).h5')\n",
    "    \n",
    "    np.set_printoptions(suppress=True)\n",
    "    \n",
    "    tm.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "    img = Image.open(img_path)\n",
    "    size = (224, 224)\n",
    "    img = ImageOps.fit(img, size, Image.ANTIALIAS)\n",
    "    image_array = np.asarray(img)\n",
    "    normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "    data[0] = normalized_image_array\n",
    "\n",
    "    tm_score = tm.predict(data)\n",
    "    \n",
    "    scores_1['tm_custom'] = tm_score\n",
    "    \n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T18:16:42.574046Z",
     "start_time": "2021-01-19T18:16:24.622464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026BBA7CAAF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026BC27FBB88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026BC283FA68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026BC3E998B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026BC3E53558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1499"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_19(img_path) ; gc.collect()\n",
    "vgg_16(img_path) ; gc.collect()\n",
    "resnet_50(img_path) ; gc.collect()\n",
    "naive_model(img_path) ; gc.collect()\n",
    "tm_model(img_path) ; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T18:16:43.066048Z",
     "start_time": "2021-01-19T18:16:42.577048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ = []\n",
    "cls_t = [] \n",
    "# 0 , 1 , 2 Where 2 means equal scores\n",
    "for key in scores_1.keys():\n",
    "    if scores_1[key][0][0]>scores_1[key][0][1]:\n",
    "        cls_t.append(0)\n",
    "        val_.append(0)\n",
    "    elif scores_1[key][0][0]<scores_1[key][0][1]:\n",
    "        val_.append(1)\n",
    "        cls_t.append(1)\n",
    "    else:\n",
    "        val_append(2)\n",
    "\n",
    "\n",
    "score_1_avg = 0\n",
    "iter_ = 0 \n",
    "for key in scores_1.keys():\n",
    "    act_val = val_[iter_]\n",
    "    score_1_avg = score_1_avg +  scores_1[key][0][act_val]\n",
    "gc.collect()\n",
    "score_1_final = (score_1_avg/5)*100\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T18:16:43.082044Z",
     "start_time": "2021-01-19T18:16:43.069048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.22226190567017"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_1_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T21:36:43.338435Z",
     "start_time": "2021-01-18T21:36:43.024258Z"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T18:16:43.370046Z",
     "start_time": "2021-01-19T18:16:43.085051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def class_finder(vgg_19,naive,btg_res,btb_vgg16,tm):\n",
    "    global vgg19_cls,naive_cls,tm_cls\n",
    "    \n",
    "    if vgg_19[0]>vgg_19[1]:\n",
    "        vgg19_cls = 0\n",
    "    else:\n",
    "        vgg19_cls = 1\n",
    "    \n",
    "        \n",
    "    if naive[0]>naive[1]:\n",
    "        naive_cls = 0\n",
    "    else:\n",
    "        naive_cls = 1\n",
    "    \n",
    "    if vgg19_cls == naive_cls:\n",
    "        \n",
    "        if vgg19_cls == 0:\n",
    "            add_on = btb_vgg16\n",
    "        else:\n",
    "            add_on = btg_res\n",
    "        return(vgg_19[vgg19_cls]+naive[vgg19_cls]+add_on[vgg19_cls])/3\n",
    "    \n",
    "    else:\n",
    "        if tm[0]>tm[1]:\n",
    "            tm_cls = 0\n",
    "            add_on = btb_vgg16\n",
    "        else:\n",
    "            tm_cls = 1\n",
    "            add_on = btg_res\n",
    "            \n",
    "        return(tm[tm_cls]+add_on[tm_cls])/2\n",
    "        \n",
    "def most_(List): \n",
    "    return max(set(List), key = List.count)\n",
    "\n",
    "def Average(lst): \n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "gc.collect()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T18:16:43.624046Z",
     "start_time": "2021-01-19T18:16:43.375049Z"
    }
   },
   "outputs": [],
   "source": [
    "#g_scores \n",
    "score_2_final_g1 = class_finder(scores_1['vgg19'][0],scores_1['resnet50'][0],scores_1['naive'][0],scores_1['vgg16'][0],scores_1['tm_custom'][0])*100\n",
    "score_2_final_g2 = class_finder(scores_1['vgg19'][0],scores_1['resnet50'][0],scores_1['tm_custom'][0],scores_1['vgg16'][0],scores_1['naive'][0])*100\n",
    "\n",
    "#b_scores\n",
    "score_2_final_b1 = class_finder(scores_1['vgg19'][0],scores_1['resnet50'][0],scores_1['naive'][0],scores_1['vgg16'][0],scores_1['tm_custom'][0])*100\n",
    "score_2_final_b2 = class_finder(scores_1['vgg19'][0],scores_1['resnet50'][0],scores_1['naive'][0],scores_1['tm_custom'][0],scores_1['vgg16'][0])*100\n",
    "\n",
    "\n",
    "try:\n",
    "    cls_list = [[tm_cls,naive_cls,vgg19_cls],cls_t]\n",
    "except Exception as e:\n",
    "    cls_list = [[naive_cls,vgg19_cls],cls_t]\n",
    "    \n",
    "    \n",
    "cls_list_n = [item for sublist in cls_list for item in sublist]\n",
    "count_0 = cls_list_n.count(0)\n",
    "count_1 = cls_list_n.count(1)\n",
    "\n",
    "gc.collect()\n",
    "perm = permutations([score_2_final_g1,score_2_final_g2,score_2_final_b1,score_2_final_b2])\n",
    "g_score = []\n",
    "b_score = []\n",
    "for lst in list(perm):\n",
    "    g_score.append(max(lst))\n",
    "    b_score.append(min(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T18:16:43.640050Z",
     "start_time": "2021-01-19T18:16:43.626047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 7)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_0,count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T18:16:43.656052Z",
     "start_time": "2021-01-19T18:16:43.643048Z"
    }
   },
   "outputs": [],
   "source": [
    "g_score = Average(g_score) \n",
    "b_score = Average(b_score)\n",
    "score_2_final = (b_score*count_0 + g_score*count_1)/(count_0+count_1)\n",
    "final_score = (score_1_final + score_2_final)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T18:16:43.688045Z",
     "start_time": "2021-01-19T18:16:43.666048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.83594266573587"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
