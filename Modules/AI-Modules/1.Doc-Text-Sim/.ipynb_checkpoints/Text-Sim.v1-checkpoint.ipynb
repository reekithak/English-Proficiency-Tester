{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DOC-SIMILARITY MODULE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T20:25:19.263028Z",
     "start_time": "2021-04-22T20:25:19.242892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 6\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "file_docs = []\n",
    "\n",
    "#Tokenize\n",
    "with open ('demofile.txt',encoding='utf-8') as f:\n",
    "    tokens = sent_tokenize(f.read())\n",
    "    for line in tokens:\n",
    "        file_docs.append(line)\n",
    "\n",
    "print(\"Number of documents:\",len(file_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T20:25:33.649614Z",
     "start_time": "2021-04-22T20:25:33.641635Z"
    }
   },
   "outputs": [],
   "source": [
    "#tokenize and create dict\n",
    "gen_docs = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in file_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T20:26:37.596238Z",
     "start_time": "2021-04-22T20:26:35.393925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{',': 0, '.': 1, 'are': 2, 'as': 3, 'determines': 4, 'document': 5, 'documents': 6, 'given': 7, 'how': 8, 'name': 9, 'similar': 10, 'similarity': 11, 'suggests': 12, 'the': 13, 'two': 14, 'a': 15, 'by': 16, 'collection': 17, 'mean': 18, 'of': 19, 'strings': 20, 'we': 21, '“': 22, '”': 23, '.txt': 24, 'an': 25, 'essay': 26, 'example': 27, 'file': 28, 'for': 29, 'or': 30, 'check': 31, 'many': 32, 'organizations': 33, 'plagiarism': 34, 'principle': 35, 'this': 36, 'to': 37, 'use': 38, 'also': 39, 'cheated': 40, 'conducting': 41, 'exams': 42, 'from': 43, 'if': 44, 'institutions': 45, 'is': 46, 'it': 47, 'other': 48, 'student': 49, 'used': 50, 'all': 51, 'important': 52, 'interesting': 53, 'know': 54, 'therefore': 55, 'very': 56, 'well': 57, 'works': 58}\n"
     ]
    }
   ],
   "source": [
    "#tokenize and create dict\n",
    "import gensim\n",
    "dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "print(dictionary.token2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
