{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T18:43:45.458198Z",
     "start_time": "2021-05-04T18:43:44.270348Z"
    }
   },
   "source": [
    "**Google Default Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:35:46.936828Z",
     "start_time": "2021-05-05T10:35:36.995473Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:36:51.091999Z",
     "start_time": "2021-05-05T10:36:51.071293Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = r'D:\\working repos\\English-Proficiency-Tester\\Working\\Modules\\AI-Modules\\1.Doc-Text-Sim\\5-4-21\\data\\GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:37:40.124726Z",
     "start_time": "2021-05-05T10:36:51.711286Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:37:40.171709Z",
     "start_time": "2021-05-05T10:37:40.124726Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class DocSim:\n",
    "    def __init__(self, w2v_model, stopwords=None):\n",
    "        self.w2v_model = w2v_model\n",
    "        self.stopwords = stopwords if stopwords is not None else []\n",
    "\n",
    "    def vectorize(self, doc: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Identify the vector values for each word in the given document\n",
    "        :param doc:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        doc = doc.lower()\n",
    "        words = [w for w in doc.split(\" \") if w not in self.stopwords]\n",
    "        word_vecs = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                vec = self.w2v_model[word]\n",
    "                word_vecs.append(vec)\n",
    "            except KeyError:\n",
    "                # Ignore, if the word doesn't exist in the vocabulary\n",
    "                pass\n",
    "\n",
    "        # Assuming that document vector is the mean of all the word vectors\n",
    "        # PS: There are other & better ways to do it.\n",
    "        vector = np.mean(word_vecs, axis=0)\n",
    "        return vector\n",
    "\n",
    "    def _cosine_sim(self, vecA, vecB):\n",
    "        \"\"\"Find the cosine similarity distance between two vectors.\"\"\"\n",
    "        csim = np.dot(vecA, vecB) / (np.linalg.norm(vecA) * np.linalg.norm(vecB))\n",
    "        if np.isnan(np.sum(csim)):\n",
    "            return 0\n",
    "        return csim\n",
    "\n",
    "    def calculate_similarity(self, source_doc, target_docs=None, threshold=0):\n",
    "        \"\"\"Calculates & returns similarity scores between given source document & all\n",
    "        the target documents.\"\"\"\n",
    "        if not target_docs:\n",
    "            return []\n",
    "\n",
    "        if isinstance(target_docs, str):\n",
    "            target_docs = [target_docs]\n",
    "\n",
    "        source_vec = self.vectorize(source_doc)\n",
    "        results = []\n",
    "        for doc in target_docs:\n",
    "            target_vec = self.vectorize(doc)\n",
    "            sim_score = self._cosine_sim(source_vec, target_vec)\n",
    "            if sim_score > threshold:\n",
    "                results.append({\"score\": sim_score, \"doc\": doc})\n",
    "            # Sort results by score in desc order\n",
    "            results.sort(key=lambda k: k[\"score\"], reverse=True)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:50:40.117130Z",
     "start_time": "2021-05-05T10:50:40.101136Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = DocSim(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:51:55.375708Z",
     "start_time": "2021-05-05T10:51:55.363708Z"
    }
   },
   "outputs": [],
   "source": [
    "source_doc = \"akhil is a good bot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:51:55.743707Z",
     "start_time": "2021-05-05T10:51:55.725707Z"
    }
   },
   "outputs": [],
   "source": [
    "target_docs = [\"akhil is a good boy\"]\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:51:56.158743Z",
     "start_time": "2021-05-05T10:51:56.146708Z"
    }
   },
   "outputs": [],
   "source": [
    "source_doc = source_doc.lower()\n",
    "target_docs[0] = target_docs[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:51:56.492706Z",
     "start_time": "2021-05-05T10:51:56.476707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.60788655, 'doc': 'akhil is a good boy'}]\n"
     ]
    }
   ],
   "source": [
    "sim_scores = ds.calculate_similarity(source_doc, target_docs)\n",
    "\n",
    "print(sim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:51:57.131707Z",
     "start_time": "2021-05-05T10:51:57.092711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60788655"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scores[0]['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternate Method - TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:41:36.903443Z",
     "start_time": "2021-05-05T10:41:36.894446Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:41:37.291512Z",
     "start_time": "2021-05-05T10:41:37.279512Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_tfidf_similarity(source_doc,target_docs):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # To make uniformed vectors, both documents need to be combined first.\n",
    "    target_docs.insert(0, source_doc)\n",
    "    embeddings = vectorizer.fit_transform(target_docs)\n",
    "\n",
    "    cosine_similarities = cosine_similarity(embeddings[0:1], embeddings[1:]).flatten()\n",
    "\n",
    "    highest_score = 0\n",
    "    highest_score_index = 0\n",
    "    for i, score in enumerate(cosine_similarities):\n",
    "        if highest_score < score:\n",
    "            highest_score = score\n",
    "            highest_score_index = i\n",
    "\n",
    "    return highest_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:41:37.775409Z",
     "start_time": "2021-05-05T10:41:37.758403Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_score = process_tfidf_similarity(source_doc,target_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T10:41:38.115165Z",
     "start_time": "2021-05-05T10:41:38.094018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3993926818249623"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sim_scores[0]['score']+tf_score)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
